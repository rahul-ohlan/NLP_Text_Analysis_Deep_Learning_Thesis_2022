{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rahul__ohlan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import json, re, sys, os\n",
    "import numpy as np\n",
    "import random as ra\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Implementing the Adept Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countPhrases(message):    \n",
    "    \n",
    "    counts = {\"*\" : 0}\n",
    "    \n",
    "    for MWE in word_tokenize(message):\n",
    "        phrase = \"\".join([block for block in MWE])\n",
    "        if re.search(\"[a-zA-Z]\", phrase):\n",
    "            counts[phrase] = counts.get(phrase,0) + 1\n",
    "            counts[\"*\"] +=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPhrases(record):   \n",
    "                                \n",
    "    \n",
    "    codes = record[\"codes\"]   \n",
    "\n",
    "\n",
    "    counts = countPhrases(record[\"tweet\"])   \n",
    "    \n",
    "\n",
    "    for code in codes:                     \n",
    "\n",
    "        codeCounts = dict(counts)\n",
    "        if code == \"null\":\n",
    "            continue\n",
    "        else:\n",
    "            if codes[code] == \"1\":\n",
    "\n",
    "                codeCounts[\"_\"+code] = 1\n",
    "                yield code,codeCounts\n",
    "\n",
    "            else:\n",
    "                codeCounts[\"_not.\" + code] =1           \n",
    "                yield \"not.\" + code,codeCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateByPhrase(d1,d2):  \n",
    "    \n",
    "    for key in d2:\n",
    "        \n",
    "        d1[key] = d1.get(key,0) + d2[key]\n",
    "        \n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEntropies(record,N):\n",
    "    code,entropies = record      \n",
    "\n",
    "    n = float(entropies[\"_N\"]) \n",
    "    entropies[\"*\"] = sum([entropies[phrase] for phrase in entropies if phrase != \"_N\" and phrase!=\"*\" and phrase!=\"_\"+code])\n",
    "                        \n",
    "    m = float(entropies[\"*\"])\n",
    "    del entropies[\"_N\"]\n",
    "    del entropies[\"*\"]\n",
    "    alpha = n/N              \n",
    "    \n",
    "    for phrase in entropies:\n",
    "        if not re.match(\"^_\",phrase):\n",
    "            entropy = -np.log2((entropies[phrase]+alpha)/(alpha*N+m))\n",
    "            entropies[phrase] = entropy\n",
    "            \n",
    "    entropies[\"_DEFAULT\"] = -np.log2(alpha/(alpha*N + m))      \n",
    "    \n",
    "    return code,entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findN(record):\n",
    "    ID,counts = record\n",
    "    yield \"_ALLCODES\",counts\n",
    "    counts[\"_N\"] = float(len(counts.keys())-1)\n",
    "    yield ID,counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet,prior_entropy,likelihoodEntropy):     \n",
    "    result = {\n",
    "        \"posteriors\" : {code: prior_entropy[code] for code in prior_entropy}, \n",
    "                                                                                   \n",
    "                                                                              \n",
    "        \"M_words\" : 0,\n",
    "        \"counts\" : dict(),     \n",
    "        \"N\" : 0,\n",
    "        \"M\" : 0,\n",
    "        \"tweet\" : tweet\n",
    "    }\n",
    "    \n",
    "    review_M = 0\n",
    "    tempCounts = countPhrases(tweet)     \n",
    "    for phrase in tempCounts:           \n",
    "        if phrase!= \"*\":\n",
    "\n",
    "            result['counts'][phrase] = result['counts'].get(phrase,0) + tempCounts[phrase]     \n",
    "            \n",
    "    todel = []\n",
    "    \n",
    "    for phrase in result['counts']:          \n",
    "        if phrase!=\"*\":\n",
    "            INLIKE = False     \n",
    "            for code in likelihoodEntropy:    \n",
    "                if likelihoodEntropy[code].get(phrase,False):    \n",
    "                    result['posteriors'][code] -= result['counts'][phrase] * likelihoodEntropy[code][phrase]\n",
    "                    INLIKE = True\n",
    "                    \n",
    "            if INLIKE:  \n",
    "                result['M'] += result['counts'][phrase] \n",
    "                result[\"M_words\"] += result['counts'][phrase] * len(re.split(\" \",phrase))\n",
    "                result[\"N\"] += 1\n",
    "                \n",
    "                for code in likelihoodEntropy:\n",
    "                    if not likelihoodEntropy[code].get(phrase,False):\n",
    "                        result['posteriors'][code] -= result['counts'][phrase]*likelihoodEntropy[code][\"_DEFAULT\"]\n",
    "                \n",
    "                result['counts'][phrase] = int(result['counts'][phrase])\n",
    "                \n",
    "            else:\n",
    "                todel.append(phrase)     \n",
    "                    \n",
    "    for phrase in todel:\n",
    "        del result['counts'][phrase]\n",
    "        \n",
    "    newPosteriors = {}\n",
    "    \n",
    "    for code in result['posteriors']:\n",
    "        splits = re.split(\"\\.\",code)     \n",
    "        if len(splits) ==2:                \n",
    "            code_val = splits[1]\n",
    "            newPosteriors.setdefault(code_val,{})\n",
    "            newPosteriors[code_val][\"0\"] = result[\"posteriors\"][code]\n",
    "            \n",
    "        else:\n",
    "            newPosteriors.setdefault(code,{})\n",
    "            newPosteriors[code][\"1\"] = result['posteriors'][code]\n",
    "            \n",
    "    result[\"posteriors\"] = newPosteriors   \n",
    "    \n",
    "    \n",
    "    for code in result['posteriors']:\n",
    "        \n",
    "        if len(result['posteriors'][code].keys()) == 2:   \n",
    "            P0 = 1/(1 + (2**( result['posteriors'][code][\"1\"]-result['posteriors'][code][\"0\"])))    \n",
    "            \n",
    "            P1 = 1 - P0\n",
    "            \n",
    "            result['posteriors'][code] = {\"0\": P0, \"1\":P1}\n",
    "            \n",
    "        else:\n",
    "            result['posteriors'][code] = {\"0\":1, \"1\":0}\n",
    "            \n",
    "    result[\"M\"] = int(result[\"M\"])\n",
    "    result[\"M_words\"] = int(result[\"M_words\"])\n",
    "    \n",
    "    \n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Training and Assessing Classifier Performance with 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\n",
    "    \"collective_force\",\n",
    "    \"collective_peace\",\n",
    "    \"singular_force\",\n",
    "    \"singular_peace\",\n",
    "    \"collective\",\n",
    "    \"singular\",\n",
    "    \"peace\",\n",
    "    \"force\",\n",
    "    \"action\"\n",
    "]\n",
    "\n",
    "thresholds = [(x)/100 for x in range(1,100)]  \n",
    "\n",
    "records = list()\n",
    "\n",
    "with open('data/naive_bayes_violent_tweets/trainingData.json','r') as redbull:\n",
    "\n",
    "    data_set = json.load(redbull)\n",
    "    for i in data_set:\n",
    "        record = data_set[i]\n",
    "\n",
    "        oldcodes = dict(record[\"codes\"])\n",
    "\n",
    "        for code in oldcodes:\n",
    "            for newcode in re.split('_',code):\n",
    "                if not record['codes'].get(newcode,0):\n",
    "                    record[\"codes\"][newcode] = oldcodes[code]\n",
    "            if not record[\"codes\"].get(\"action\",0):\n",
    "                record[\"codes\"][\"action\"] = oldcodes[code]\n",
    "        records.append(record)\n",
    "\n",
    "ra.seed(30)\n",
    "\n",
    "ra.shuffle(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the results for fold : 0\n",
      "collective_force 0.01 1.0 0.17012814847547503 0.290785498489426 0.17012814847547503\n",
      "collective_peace 0.01 1.0 0.10561201944321696 0.19104716227018384 0.10561201944321696\n",
      "singular_force 0.01 1.0 0.11356606274856386 0.20396825396825397 0.11356606274856386\n",
      "singular_peace 0.01 1.0 0.4158197083517455 0.5873907615480649 0.4158197083517455\n",
      "collective 0.01 1.0 0.10561201944321696 0.19104716227018384 0.10561201944321696\n",
      "singular 0.01 1.0 0.4158197083517455 0.5873907615480649 0.4158197083517455\n",
      "peace 0.01 1.0 0.4158197083517455 0.5873907615480649 0.4158197083517455\n",
      "force 0.01 1.0 0.11356606274856386 0.20396825396825397 0.11356606274856386\n",
      "action 0.01 1.0 0.4158197083517455 0.5873907615480649 0.4158197083517455\n",
      "the results for fold : 1\n",
      "collective_force 0.01 1.0 0.16836058329650905 0.2881996974281391 0.16836058329650905\n",
      "collective_peace 0.01 1.0 0.1100309323906319 0.19824840764331209 0.1100309323906319\n",
      "singular_force 0.01 1.0 0.12152010605391074 0.21670606776989754 0.12152010605391074\n",
      "singular_peace 0.01 1.0 0.4122845779938135 0.5838548185231539 0.4122845779938135\n",
      "collective 0.01 1.0 0.1100309323906319 0.19824840764331209 0.1100309323906319\n",
      "singular 0.01 1.0 0.4122845779938135 0.5838548185231539 0.4122845779938135\n",
      "peace 0.01 1.0 0.4122845779938135 0.5838548185231539 0.4122845779938135\n",
      "force 0.01 1.0 0.12152010605391074 0.21670606776989754 0.12152010605391074\n",
      "action 0.01 1.0 0.4122845779938135 0.5838548185231539 0.4122845779938135\n",
      "the results for fold : 2\n",
      "collective_force 0.01 1.0 0.16261599646486966 0.2797415431394907 0.16261599646486966\n",
      "collective_peace 0.01 1.0 0.09809986743261158 0.17867203219315894 0.09809986743261158\n",
      "singular_force 0.01 1.0 0.12019443216968625 0.21459566074950692 0.12019443216968625\n",
      "singular_peace 0.01 1.0 0.41140079540433055 0.582968065122104 0.41140079540433055\n",
      "collective 0.01 1.0 0.09809986743261158 0.17867203219315894 0.09809986743261158\n",
      "singular 0.01 1.0 0.41140079540433055 0.582968065122104 0.41140079540433055\n",
      "peace 0.01 1.0 0.41140079540433055 0.582968065122104 0.41140079540433055\n",
      "force 0.01 1.0 0.12019443216968625 0.21459566074950692 0.12019443216968625\n",
      "action 0.01 1.0 0.41140079540433055 0.582968065122104 0.41140079540433055\n",
      "the results for fold : 3\n",
      "collective_force 0.01 1.0 0.1794078656650464 0.30423379542899964 0.1794078656650464\n",
      "collective_peace 0.01 1.0 0.12682280159080866 0.2250980392156863 0.12682280159080866\n",
      "singular_force 0.01 1.0 0.11091471498011489 0.19968178202068418 0.11091471498011489\n",
      "singular_peace 0.01 1.0 0.43305346884666374 0.6043786617329633 0.43305346884666374\n",
      "collective 0.01 1.0 0.12682280159080866 0.2250980392156863 0.12682280159080866\n",
      "singular 0.01 1.0 0.43305346884666374 0.6043786617329633 0.43305346884666374\n",
      "peace 0.01 1.0 0.43305346884666374 0.6043786617329633 0.43305346884666374\n",
      "force 0.01 1.0 0.11091471498011489 0.19968178202068418 0.11091471498011489\n",
      "action 0.01 1.0 0.43305346884666374 0.6043786617329633 0.43305346884666374\n",
      "the results for fold : 4\n",
      "collective_force 0.01 1.0 0.172779496243924 0.2946495855312736 0.172779496243924\n",
      "collective_peace 0.01 1.0 0.11975254087494476 0.2138910812943962 0.11975254087494476\n",
      "singular_force 0.01 1.0 0.1241714538223597 0.22091194968553457 0.1241714538223597\n",
      "singular_peace 0.01 1.0 0.4308440123729563 0.6022235948116121 0.4308440123729563\n",
      "collective 0.01 1.0 0.11975254087494476 0.2138910812943962 0.11975254087494476\n",
      "singular 0.01 1.0 0.4308440123729563 0.6022235948116121 0.4308440123729563\n",
      "peace 0.01 1.0 0.4308440123729563 0.6022235948116121 0.4308440123729563\n",
      "force 0.01 1.0 0.1241714538223597 0.22091194968553457 0.1241714538223597\n",
      "action 0.01 1.0 0.4308440123729563 0.6022235948116121 0.4308440123729563\n",
      "the results for fold : 5\n",
      "collective_force 0.01 1.0 0.17012814847547503 0.290785498489426 0.17012814847547503\n",
      "collective_peace 0.01 1.0 0.12107821475916924 0.21600315333070555 0.12107821475916924\n",
      "singular_force 0.01 1.0 0.12152010605391074 0.21670606776989754 0.12152010605391074\n",
      "singular_peace 0.01 1.0 0.4140521431727795 0.585625 0.4140521431727795\n",
      "collective 0.01 1.0 0.12107821475916924 0.21600315333070555 0.12107821475916924\n",
      "singular 0.01 1.0 0.4140521431727795 0.585625 0.4140521431727795\n",
      "peace 0.01 1.0 0.4140521431727795 0.585625 0.4140521431727795\n",
      "force 0.01 1.0 0.12152010605391074 0.21670606776989754 0.12152010605391074\n",
      "action 0.01 1.0 0.4140521431727795 0.585625 0.4140521431727795\n",
      "the results for fold : 6\n",
      "collective_force 0.01 1.0 0.16482545293857712 0.2830045523520486 0.16482545293857712\n",
      "collective_peace 0.01 1.0 0.11577551922227132 0.20752475247524751 0.11577551922227132\n",
      "singular_force 0.01 1.0 0.1303579319487406 0.23064894448788112 0.1303579319487406\n",
      "singular_peace 0.01 1.0 0.4078656650463986 0.5794099183929693 0.4078656650463986\n",
      "collective 0.01 1.0 0.11577551922227132 0.20752475247524751 0.11577551922227132\n",
      "singular 0.01 1.0 0.4078656650463986 0.5794099183929693 0.4078656650463986\n",
      "peace 0.01 1.0 0.4078656650463986 0.5794099183929693 0.4078656650463986\n",
      "force 0.01 1.0 0.1303579319487406 0.23064894448788112 0.1303579319487406\n",
      "action 0.01 1.0 0.4078656650463986 0.5794099183929693 0.4078656650463986\n",
      "the results for fold : 7\n",
      "collective_force 0.01 1.0 0.17631462660185596 0.2997746055597295 0.17631462660185596\n",
      "collective_peace 0.01 1.0 0.11312417145382236 0.203255260023819 0.11312417145382236\n",
      "singular_force 0.01 1.0 0.12859036676977464 0.22787783868441663 0.12859036676977464\n",
      "singular_peace 0.01 1.0 0.4507291206363235 0.6213828815108132 0.4507291206363235\n",
      "collective 0.01 1.0 0.11312417145382236 0.203255260023819 0.11312417145382236\n",
      "singular 0.01 1.0 0.4507291206363235 0.6213828815108132 0.4507291206363235\n",
      "peace 0.01 1.0 0.4507291206363235 0.6213828815108132 0.4507291206363235\n",
      "force 0.01 1.0 0.12859036676977464 0.22787783868441663 0.12859036676977464\n",
      "action 0.01 1.0 0.4507291206363235 0.6213828815108132 0.4507291206363235\n",
      "the results for fold : 8\n",
      "collective_force 0.01 1.0 0.1661511268228016 0.2849564228874574 0.1661511268228016\n",
      "collective_peace 0.01 1.0 0.10914714980114892 0.19681274900398407 0.10914714980114892\n",
      "singular_force 0.01 1.0 0.11621741051701281 0.2082343626286619 0.11621741051701281\n",
      "singular_peace 0.01 1.0 0.4410075121520106 0.6120821833793315 0.4410075121520106\n",
      "collective 0.01 1.0 0.10914714980114892 0.19681274900398407 0.10914714980114892\n",
      "singular 0.01 1.0 0.4410075121520106 0.6120821833793315 0.4410075121520106\n",
      "peace 0.01 1.0 0.4410075121520106 0.6120821833793315 0.4410075121520106\n",
      "force 0.01 1.0 0.11621741051701281 0.2082343626286619 0.11621741051701281\n",
      "action 0.01 1.0 0.4410075121520106 0.6120821833793315 0.4410075121520106\n",
      "the results for fold : 9\n",
      "collective_force 0.01 1.0 0.19530558015943314 0.3267876991478325 0.19530558015943314\n",
      "collective_peace 0.01 1.0 0.1337466784765279 0.2359375 0.1337466784765279\n",
      "singular_force 0.01 1.0 0.1403897254207263 0.24621359223300973 0.1403897254207263\n",
      "singular_peace 0.01 1.0 0.4366696191319752 0.6078914919852034 0.4366696191319752\n",
      "collective 0.01 1.0 0.1337466784765279 0.2359375 0.1337466784765279\n",
      "singular 0.01 1.0 0.4366696191319752 0.6078914919852034 0.4366696191319752\n",
      "peace 0.01 1.0 0.4366696191319752 0.6078914919852034 0.4366696191319752\n",
      "force 0.01 1.0 0.1403897254207263 0.24621359223300973 0.1403897254207263\n",
      "action 0.01 1.0 0.4366696191319752 0.6078914919852034 0.4366696191319752\n"
     ]
    }
   ],
   "source": [
    "numfolds = 10    \n",
    "folds = []\n",
    "\n",
    "foldsize = int((len(records)/numfolds) + 0.5 )      \n",
    "if foldsize * numfolds < len(records):    \n",
    "    foldsize += 1\n",
    "\n",
    "allresults = []\n",
    "\n",
    "for foldnum in range(numfolds):      \n",
    "    \n",
    "    trainingrecords = []            \n",
    "    testingrecords = []\n",
    "    \n",
    "    for k in range(numfolds):\n",
    "        \n",
    "        if k==foldnum:\n",
    "            testingrecords.extend(list(records[k*foldsize : (k+1)*foldsize]))\n",
    "            \n",
    "        else:\n",
    "            trainingrecords.extend(list(records[k*foldsize : (k+1)*foldsize]))\n",
    "\n",
    "    # ************** training begins here with the first trainingrecords dataset **************\n",
    "\n",
    "    allcounts = {}             \n",
    "    for code in codes:\n",
    "        allcounts[code] = {}\n",
    "        allcounts[\"not.\"+code] = {}\n",
    "\n",
    "    total_tweets = 0\n",
    "    \n",
    "    for record in trainingrecords:        \n",
    "        total_tweets += 1                 \n",
    "        for k,v in loadPhrases(record):   \n",
    "            allcounts[k] = aggregateByPhrase(allcounts[k],v)\n",
    "            \n",
    "    for code in codes:\n",
    "        allcounts['_ALLCODES'] = aggregateByPhrase(dict(allcounts[code]), allcounts[\"not.\"+code])\n",
    "        break\n",
    "        \n",
    "    for ky in allcounts.keys():\n",
    "        allcounts[ky][\"_N\"] = float(len(allcounts[ky].keys()) -1)\n",
    "        \n",
    "    N = float(len(allcounts[\"_ALLCODES\"].keys())) -2\n",
    "    \n",
    "    \n",
    "    del allcounts[\"_ALLCODES\"]\n",
    "    \n",
    "    entropies = list()\n",
    "\n",
    "    for ky in allcounts.keys():\n",
    "        entropies.append(computeEntropies((ky,dict(allcounts[ky])),N))\n",
    "        \n",
    "    likelihoodEntropy = {}\n",
    "    prior_entropy = {}\n",
    "\n",
    "    for x in entropies:\n",
    "        code = x[0]   \n",
    "        entdict = dict(x[1])    \n",
    "\n",
    "        priorNum = entdict.get(\"_\"+code,0)\n",
    "        prior_entropy[code] = priorNum\n",
    "                            \n",
    "        entdict.pop(\"_\"+code,None)\n",
    "        \n",
    "        likelihoodEntropy[code] = dict(entdict) \n",
    "\n",
    "    for code in prior_entropy:\n",
    "        if prior_entropy[code] != 0:   \n",
    "\n",
    "            prior_entropy[code] = -np.log2(prior_entropy[code]/total_tweets)\n",
    "\n",
    "    \n",
    "    #### Testing Begins Here\n",
    "\n",
    "    totals = {}\n",
    "\n",
    "    for code in codes:\n",
    "        totals[code] = {}      # code is each of the 9 classes now , empty value dict created for each class\n",
    "        for thresh in thresholds:\n",
    "            totals[code][str(thresh)] = {\n",
    "                \"TP\" : 0,\n",
    "                \"FP\" : 0,\n",
    "                \"FN\" : 0,\n",
    "                \"TN\" : 0\n",
    "            }\n",
    "\n",
    "\n",
    "    for record in testingrecords:\n",
    "        result = processTweet(record[\"tweet\"],prior_entropy,likelihoodEntropy)\n",
    "        \n",
    "        for code in codes:\n",
    "            truth = record[\"codes\"][code]       # assume truth is one, say for collective_force -> it'll be 1 for collective, force and action as well\n",
    "            for thresh in thresholds:\n",
    "                \n",
    "                st = str(thresh)\n",
    "                \n",
    "                if result[\"posteriors\"][code][\"1\"] >= thresh:     # assume if posterior probability of this tweet to be in this class = 0.46\n",
    "                    prediction = 1\n",
    "                else:\n",
    "                    prediction = 0                           # prediction will stay 0 till our thresh reaches 0.46\n",
    "                    \n",
    "                if truth:\n",
    "                    if prediction:\n",
    "                        totals[code][st][\"TP\"] +=1\n",
    "                        \n",
    "                    else:\n",
    "                        totals[code][st][\"FN\"] +=1\n",
    "                                                        \n",
    "\n",
    "                        \n",
    "                else:\n",
    "                    if prediction:\n",
    "                        totals[code][st][\"FP\"] +=1\n",
    "                        \n",
    "                        \n",
    "                    else:\n",
    "                        totals[code][st][\"TN\"] +=1 \n",
    "    \n",
    "    \n",
    "    for code in codes:         # Calculating the classification measures\n",
    "                                # eth works just fine till here\n",
    "        for thresh in thresholds:\n",
    "            st = str(thresh)\n",
    "            \n",
    "            try:\n",
    "                totals[code][st][\"TPR\"] = totals[code][st][\"TP\"]/(totals[code][st][\"TP\"] + totals[code][st][\"FN\"])    #TPR is recall = TP/(TP+FN)\n",
    "            except:\n",
    "                totals[code][st][\"TPR\"] = 0\n",
    "                \n",
    "                \n",
    "            try:\n",
    "                totals[code][st][\"PPV\"] = totals[code][st][\"TP\"]/(totals[code][st][\"TP\"]+totals[code][st][\"FP\"])      # PPV is precision = TP/(TP+FP)\n",
    "            \n",
    "            except:\n",
    "                totals[code][st][\"PPV\"] = 0\n",
    "                \n",
    "                \n",
    "            try:\n",
    "                totals[code][st][\"F1\"] = (2*totals[code][st][\"TPR\"]*totals[code][st][\"PPV\"])/(\n",
    "                totals[code][st][\"TPR\"] + totals[code][st][\"PPV\"])\n",
    "                \n",
    "            except:\n",
    "                totals[code][st][\"F1\"] = 0\n",
    "                \n",
    "            try:\n",
    "                totals[code][st][\"ACC\"] = (totals[code][st][\"TP\"]+totals[code][st][\"TN\"])/(                                            #ACC is Accuracy = (TP+TN)/(Total Predictions)\n",
    "                totals[code][st][\"TP\"] + totals[code][st][\"TN\"] + totals[code][st][\"FP\"]+ totals[code][st][\"FN\"])\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                totals[code][st][\"ACC\"] = 0\n",
    "\n",
    "    print(\"the results for fold : \" + str(foldnum))\n",
    "\n",
    "    for code in codes:\n",
    "            st = max([(totals[code][str(thresh)][\"F1\"], str(thresh)) for thresh in thresholds], key = lambda x: x[0])[1]\n",
    "            \n",
    "            totals[code][\"thresh\"] = st\n",
    "            \n",
    "            print(code,st,totals[code][st][\"PPV\"], totals[code][st][\"TPR\"], totals[code][st][\"F1\"], totals[code][st][\"ACC\"])\n",
    "            \n",
    "            # print(allresults.append(totals))\n",
    "\n",
    "    allresults.append(totals)\n",
    "\n",
    "    # print(allresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collective_force': [0.01, 0.29429188984538224], 'collective_peace': [0.01, 0.20664901374504935], 'singular_force': [0.01, 0.2185544519997744], 'singular_peace': [0.01, 0.5967207377006216], 'collective': [0.01, 0.20664901374504935], 'singular': [0.01, 0.5967207377006216], 'peace': [0.01, 0.5967207377006216], 'force': [0.01, 0.2185544519997744], 'action': [0.01, 0.5967207377006216]}\n"
     ]
    }
   ],
   "source": [
    "bestThresh = {}\n",
    "for code in codes:\n",
    "    bestThresh[code] = [0, 0]\n",
    "    for thresh in thresholds:\n",
    "        F1 = np.mean([totals[code][str(thresh)][\"F1\"] for totals in allresults])\n",
    "        \n",
    "        if F1 > bestThresh[code][1]:\n",
    "            bestThresh[code] = [thresh,F1]\n",
    "            \n",
    "    thresh = bestThresh[code][0]\n",
    "        \n",
    "        # print(code,thresh,np.mean([totals[code][str(thresh)][\"PPV\"] for totals in allresults]),\n",
    "        #      np.mean([totals[code][str(thresh)][\"TPR\"] for totals in allresults]),\n",
    "        #      np.mean([totals[code][str(thresh)][\"F1\"] for totals in allresults]))\n",
    "print(bestThresh)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95c8aa7dc74b950936004c3f3c391ccf15d01df31e665f664ea6f8b7a68af41b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
